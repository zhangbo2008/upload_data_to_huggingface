{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm instruction-tuned-sd -rf\n!git clone https://github.com/huggingface/instruction-tuned-sd\n","metadata":{"execution":{"iopub.status.busy":"2023-06-05T03:29:07.942920Z","iopub.execute_input":"2023-06-05T03:29:07.943288Z","iopub.status.idle":"2023-06-05T03:29:10.788113Z","shell.execute_reply.started":"2023-06-05T03:29:07.943255Z","shell.execute_reply":"2023-06-05T03:29:10.786653Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'instruction-tuned-sd'...\nremote: Enumerating objects: 170, done.\u001b[K\nremote: Counting objects: 100% (107/107), done.\u001b[K\nremote: Compressing objects: 100% (72/72), done.\u001b[K\nremote: Total 170 (delta 61), reused 58 (delta 35), pack-reused 63\u001b[K\nReceiving objects: 100% (170/170), 67.53 KiB | 7.50 MiB/s, done.\nResolving deltas: 100% (85/85), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"cd instruction-tuned-sd","metadata":{"execution":{"iopub.status.busy":"2023-06-05T03:29:10.792475Z","iopub.execute_input":"2023-06-05T03:29:10.792877Z","iopub.status.idle":"2023-06-05T03:29:10.800979Z","shell.execute_reply.started":"2023-06-05T03:29:10.792845Z","shell.execute_reply":"2023-06-05T03:29:10.799876Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/instruction-tuned-sd\n","output_type":"stream"}]},{"cell_type":"code","source":"cd data_preparation","metadata":{"execution":{"iopub.status.busy":"2023-06-05T03:29:10.803184Z","iopub.execute_input":"2023-06-05T03:29:10.804223Z","iopub.status.idle":"2023-06-05T03:29:10.812023Z","shell.execute_reply.started":"2023-06-05T03:29:10.804188Z","shell.execute_reply":"2023-06-05T03:29:10.810813Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working/instruction-tuned-sd/data_preparation\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-06-05T03:29:10.815412Z","iopub.execute_input":"2023-06-05T03:29:10.816363Z","iopub.status.idle":"2023-06-05T03:29:23.092919Z","shell.execute_reply.started":"2023-06-05T03:29:10.816329Z","shell.execute_reply":"2023-06-05T03:29:23.091561Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.12.0)\nRequirement already satisfied: tensorflow_datasets==4.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.6.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.11.0)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.14.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.23.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (9.5.0)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (4.5.4.60)\nRequirement already satisfied: protobuf==3.20.* in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (3.20.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (1.4.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (0.3.6)\nRequirement already satisfied: etils[epath] in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (1.2.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (2.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (2.28.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (1.16.0)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (0.14.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (2.3.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (0.10.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (4.64.1)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (23.3.3)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (3.8.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (0.4.10)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (2.12.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (16.0.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (59.8.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (2.12.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (4.5.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 1)) (0.31.0)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (10.0.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (2023.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (5.4.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 4)) (3.12.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 1)) (0.40.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.1)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->-r requirements.txt (line 1)) (0.1.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->-r requirements.txt (line 1)) (1.10.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (2023.5.7)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (2.3.4)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (5.12.0)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (3.15.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow_datasets==4.6.0->-r requirements.txt (line 2)) (1.57.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 1)) (3.2.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\nimport argparse\nimport hashlib\nimport os\n\nimport model_utils\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom PIL import Image\nfrom tqdm import tqdm\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"Prepare a dataset for InstructPix2Pix style training.\"\n    )\n    parser.add_argument(\n        \"--model_id\", type=str, default=\"sayakpaul/whitebox-cartoonizer\"\n    )\n    parser.add_argument(\"--dataset_id\", type=str, default=\"imagenette\")\n    parser.add_argument(\"--max_num_samples\", type=int, default=50)\n    parser.add_argument(\"--data_root\", type=str, default=\"cartoonizer-dataset\")\n    args = parser.parse_known_args()[0]\n    return args\n\n\ndef load_dataset(dataset_id: str, max_num_samples: int) -> tf.data.Dataset:\n    dataset = tfds.load(dataset_id, split=\"train\")\n    dataset = dataset.shuffle(max_num_samples if max_num_samples is not None else 128)\n    if max_num_samples is not None:\n        print(f\"Dataset will be restricted to {max_num_samples} samples.\")\n        dataset = dataset.take(max_num_samples)\n    return dataset\n\n\ndef main(args):\n    print(\"Loading initial dataset and the Cartoonizer model...\")\n    dataset = load_dataset(args.dataset_id, args.max_num_samples)\n    concrete_fn = model_utils.load_model(args.model_id)\n    inference_fn = model_utils.perform_inference(concrete_fn)\n\n    print(\"Preparing the image pairs...\")\n    os.makedirs(args.data_root, exist_ok=True)\n    for sample in tqdm(dataset.as_numpy_iterator()):\n        original_image = sample[\"image\"]\n        cartoonized_image = inference_fn(original_image)\n\n        hash_image = hashlib.sha1(original_image.tobytes()).hexdigest()\n        sample_dir = os.path.join(args.data_root, hash_image)\n        os.makedirs(sample_dir,exist_ok=True)\n\n        original_image = Image.fromarray(original_image).convert(\"RGB\")\n        original_image.save(os.path.join(sample_dir, \"original_image.png\"))\n        cartoonized_image.save(os.path.join(sample_dir, \"cartoonized_image.png\"))\n\n    print(f\"Total generated image-pairs: {len(os.listdir(args.data_root))}.\")\n\n\nif __name__ == \"__main__\":\n    args = parse_args()\n#     args=argparse.ArgumentParser().parse_known_args()[0]\n    main(args)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T03:29:23.096047Z","iopub.execute_input":"2023-06-05T03:29:23.096421Z","iopub.status.idle":"2023-06-05T03:30:43.137960Z","shell.execute_reply.started":"2023-06-05T03:29:23.096383Z","shell.execute_reply":"2023-06-05T03:30:43.136631Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Loading initial dataset and the Cartoonizer model...\n\u001b[1mDownloading and preparing dataset 1.45 GiB (download: 1.45 GiB, generated: 1.46 GiB, total: 2.91 GiB) to ~/tensorflow_datasets/imagenette/full-size-v2/1.0.0...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d58e46b4ef534822ba5f95e1893578ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6704efc877d430fab0e0bdca86755ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extraction completed...: 0 file [00:00, ? file/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65cf5fee2d6341c6910efe59db1e8bb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c577367d2be44782b14c06b5bf4006c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train examples...:   0%|          | 0/9469 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f6d3008f49545c188e0ac1fd55ffed0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling ~/tensorflow_datasets/imagenette/full-size-v2/1.0.0.incomplete2XG8G5/imagenette-train.tfrecord*...: …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17bae988191543ad8b9fe63b4b763a38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation examples...:   0%|          | 0/3925 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d5df5965e3b4840b5825dcf054aeab9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling ~/tensorflow_datasets/imagenette/full-size-v2/1.0.0.incomplete2XG8G5/imagenette-validation.tfrecord*…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43ab42a6b5fe45858a46a4ba7a305bff"}},"metadata":{}},{"name":"stdout","text":"\u001b[1mDataset imagenette downloaded and prepared to ~/tensorflow_datasets/imagenette/full-size-v2/1.0.0. Subsequent calls will reuse this data.\u001b[0m\nDataset will be restricted to 50 samples.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c743a46b803f4924915ea6248b2903bc"}},"metadata":{}},{"name":"stdout","text":"Preparing the image pairs...\n","output_type":"stream"},{"name":"stderr","text":"50it [00:31,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Total generated image-pairs: 50.\n","output_type":"stream"}]},{"cell_type":"code","source":"!huggingface-cli login --token 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 --add-to-git-credential  # token里面是自己的配置. https://huggingface.co/settings/tokens 点newtoken_然后设置为write属性.","metadata":{"execution":{"iopub.status.busy":"2023-06-05T03:30:43.139764Z","iopub.execute_input":"2023-06-05T03:30:43.140773Z","iopub.status.idle":"2023-06-05T03:30:44.683934Z","shell.execute_reply.started":"2023-06-05T03:30:43.140727Z","shell.execute_reply":"2023-06-05T03:30:44.682736Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Token is valid.\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install datasets==2.11.0\nimport argparse\nimport os\nfrom typing import List\n\nimport numpy as np\nfrom datasets import Dataset, Features\nfrom datasets import Image as ImageFeature\nfrom datasets import Value\n\nDS_NAME = \"cartoonizer-dataset\"\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--data_root\", type=str, default=\"cartoonizer-dataset\")\n    parser.add_argument(\"--instructions_path\", type=str, default=\"instructions.txt\")\n    args=parser.parse_known_args()[0]\n    return args\n\n\ndef load_instructions(instructions_path: str) -> List[str]:\n    with open(instructions_path, \"r\") as f:\n        instructions = f.readlines()\n    instructions = [i.strip() for i in instructions]\n    return instructions\n\n\ndef generate_examples(data_paths: List[str], instructions: List[str]):\n    def fn():\n        for data_path in data_paths:\n            yield {\n                \"original_image\": {\"path\": data_path[0]},\n                \"edit_prompt\": np.random.choice(instructions),\n                \"cartoonized_image\": {\"path\": data_path[1]},\n            }\n\n    return fn\n\n\ndef main(args):\n    instructions = load_instructions(args.instructions_path)\n\n    data_paths = os.listdir(args.data_root)\n    data_paths = [os.path.join(args.data_root, d) for d in data_paths]\n    new_data_paths = []\n    for data_path in data_paths:\n        original_image = os.path.join(data_path, \"original_image.png\")\n        cartoonized_image = os.path.join(data_path, \"cartoonized_image.png\")\n        new_data_paths.append((original_image, cartoonized_image))\n\n    generation_fn = generate_examples(new_data_paths, instructions)\n    print(\"Creating dataset...\")\n    ds = Dataset.from_generator(\n        generation_fn,\n        features=Features(\n            original_image=ImageFeature(),\n            edit_prompt=Value(\"string\"),\n            cartoonized_image=ImageFeature(),\n        ),\n    )\n\n    print(\"Pushing to the Hub...\")\n    ds.push_to_hub(DS_NAME)\n\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    main(args)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T03:30:44.686812Z","iopub.execute_input":"2023-06-05T03:30:44.687330Z","iopub.status.idle":"2023-06-05T03:31:00.619122Z","shell.execute_reply.started":"2023-06-05T03:30:44.687289Z","shell.execute_reply":"2023-06-05T03:31:00.618082Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets==2.11.0 in /opt/conda/lib/python3.10/site-packages (2.11.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (10.0.1)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (2.28.2)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (4.64.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (2023.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (0.14.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (0.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (5.4.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11.0) (3.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11.0) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.11.0) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11.0) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11.0) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.11.0) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCreating dataset...\nDownloading and preparing dataset generator/default to /root/.cache/huggingface/datasets/generator/default-0854825ace59f3dd/0.0.0...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"490b4a87fe5e4ace92b7d6cb4b2a0fb7"}},"metadata":{}},{"name":"stdout","text":"Dataset generator downloaded and prepared to /root/.cache/huggingface/datasets/generator/default-0854825ace59f3dd/0.0.0. Subsequent calls will reuse this data.\nPushing to the Hub...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81f6de1b8053422e9c9cd9e6cc00bfd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57c46af7f6f04e7abe6cac9634cca023"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab1295a4ed7c47cbb585d6f9dda1fb98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c43818ae4fe04d0a8947b6a9e102598d"}},"metadata":{}}]},{"cell_type":"code","source":"#  成功push到了  https://huggingface.co/datasets/zhangbo2008/cartoonizer-dataset !!!!!!!!!!","metadata":{},"execution_count":null,"outputs":[]}]}